{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gomesgr2/PLN-Projects/blob/main/Copy_of_2023_Q3_PLN_ATIVIDADE_PR%C3%81TICA_05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6QILOdpOjwv"
      },
      "source": [
        "# **Processamento de Linguagem Natural [2023.Q3]**\n",
        "Prof. Alexandre Donizeti Alves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m67OOx9MX_3"
      },
      "source": [
        "### **ATIVIDADE PRÁTICA 05 [LangChain + Grandes Modelos de Linguagem + API]**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Gk0nHKabBT-"
      },
      "source": [
        "A **ATIVIDADE PRÁTICA 05** deve ser feita utilizando o **Google Colab** com uma conta sua vinculada ao Gmail. O link do seu notebook, armazenado no Google Drive, além do link de um repositório no GitHub e os principais resultados da atividade, devem ser enviados usando o seguinte formulário:\n",
        "\n",
        "> https://forms.gle/C1oUi1FKTZ4W9fNdA\n",
        "\n",
        "\n",
        "**IMPORTANTE**: A submissão deve ser feita até o dia **10/12 (domingo)** APENAS POR UM INTEGRANTE DA EQUIPE, até às 23h59. Por favor, lembre-se de dar permissão de ACESSO IRRESTRITO para o professor da disciplina de PLN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7hJlilKM485"
      },
      "source": [
        "### **EQUIPE**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnIArN0QY-Ek"
      },
      "source": [
        "**POR FAVOR, PREENCHER OS INTEGRANDES DA SUA EQUIPE:**\n",
        "\n",
        "\n",
        "**Integrante 01:**\n",
        "\n",
        "`Amanda Melati Kuvasney 11201811735`\n",
        "\n",
        "**Integrante 02:**\n",
        "\n",
        "`Beatriz Domingos de Oliveira 11202130893`\n",
        "\n",
        "**Integrante 03:**\n",
        "\n",
        "`Gabriel Gomes de Oliveira Costa 11201921471`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbYD2mw8y4CN"
      },
      "source": [
        "### **GRANDE MODELO DE LINGUAGEM (*Large Language Model - LLM*)**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UlblxFxzDV-"
      },
      "source": [
        "Cada equipe deve selecionar um Grande Modelo de Linguagem (*Large Language Model - LMM*). Preferencialmente, usar um modelo gratuito. Cada modelo pode ser escolhido por até 4 equipes.\n",
        "\n",
        ">\n",
        "\n",
        "Uma lista de LLMs está disponível em:\n",
        "\n",
        "> https://integrations.langchain.com/llms\n",
        "> https://python.langchain.com/docs/integrations/llms/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVpiVhzn3QqE"
      },
      "source": [
        "**Modelos da Hugging Face:**\n",
        "\n",
        "* Mistral Base: modelo promissor.\n",
        "\n",
        "> https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1\n",
        "\n",
        "* Mistral Quantizado: mais leve. Pode ser um pouco mais difícil de configurar, mas deve ocupar menos memória.\n",
        "\n",
        "> https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF\n",
        "\n",
        "* Mistral Lite da Amazon: pode ter desempenho melhor.\n",
        "\n",
        "> https://huggingface.co/amazon/MistralLite\n",
        "\n",
        "* Llama 2 7B: modelo da Meta melhorado.\n",
        "\n",
        "> https://huggingface.co/meta-llama/Llama-2-7b-chat-hf\n",
        "\n",
        "* Llama 2 7b 32k: contexto maior pelo mesmo tamanho.\n",
        "\n",
        "> https://huggingface.co/togethercomputer/Llama-2-7B-32K-Instruct\n",
        "\n",
        "* Galactica: para artigos científicos\n",
        "\n",
        "> https://huggingface.co/facebook/galactica-6.7b\n",
        "\n",
        "* Alpaca: alternativo ao Llama\n",
        "\n",
        "> https://huggingface.co/chavinlo/alpaca-native\n",
        "\n",
        "> https://huggingface.co/spaces/tloen/alpaca-lora"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRuAiSr05Ayt"
      },
      "source": [
        "**Lista de Modelos Interessantes:**\n",
        "\n",
        "> https://www.kdnuggets.com/2023/04/8-opensource-alternative-chatgpt-bard.html\n",
        "\n",
        "* Vicuna:\n",
        "> https://huggingface.co/lmsys/vicuna-7b-v1.5-16k\n",
        "\n",
        "* Openchat kit:\n",
        "> https://huggingface.co/togethercomputer/GPT-NeoXT-Chat-Base-20B\n",
        "\n",
        "* Meta OPT:\n",
        "> https://huggingface.co/facebook/opt-1.3b\n",
        "\n",
        "* Google Flan:\n",
        "> https://huggingface.co/google/flan-t5-base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Q3mhqda5WP1"
      },
      "source": [
        "**APIs:**\n",
        "\n",
        "* GPT4ALL: tenta ser um chatGPT aberto\n",
        "> https://python.langchain.com/docs/integrations/llms/gpt4all\n",
        "\n",
        "* YandexGPT: da empresa russa que criou um modelo de *Machine Learning* clássico muito bom, o CatBoost.\n",
        "> https://python.langchain.com/docs/integrations/llms/yandex\n",
        "\n",
        "* Anthropic: empresa forte concorrente da OpenAi.\n",
        "> https://python.langchain.com/docs/integrations/chat/anthropic\n",
        "\n",
        "* Gorilla: pipeline para geração de código\n",
        " > https://www.kdnuggets.com/2023/06/meet-gorilla-uc-berkeley-microsoft-apiaugmented-llm-outperforms-gpt4-chatgpt-claude.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DO6XMjHx58u9"
      },
      "source": [
        "**IMPORTANTE**: todo esse levantamento e comentários foram feitos pelo aluno  **Bruno Sanches Rodrigues**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6AkE6iW0c3o"
      },
      "source": [
        "Por favor, informe os dados do LLM selecionada:\n",
        "\n",
        ">\n",
        "\n",
        "\n",
        "**LLM**: https://huggingface.co/google/flan-t5-base\n",
        "\n",
        ">\n",
        "\n",
        "**Link para a documentação oficial**: https://huggingface.co/google/flan-t5-base\n",
        "\n",
        ">\n",
        "\n",
        "\n",
        "**Site oficial (GitHub)**:https://github.com/google-research/t5x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2oo8GtK0xSO"
      },
      "source": [
        "**IMPORTANTE**: não pode ser o modelo da `OpenAI`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yExhaebs-nD"
      },
      "source": [
        "### **API**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjJM_qhEZRy6"
      },
      "source": [
        "Por favor, informe os dados da API selecionada:\n",
        "\n",
        "**API**: News API\n",
        "\n",
        "**Site oficial**: https://newsapi.org\n",
        "\n",
        "**Link para a documentação oficial**: https://newsapi.org/docs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTODq98Myt_u"
      },
      "source": [
        "**IMPORTANTE**: não é necessário usar a mesma **API** da `ATIVIDADE PRÁTICA 03`. Cada **API** pode ser usada por até 4 equipes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtjgWQRzNphL"
      },
      "source": [
        "### **DESCRIÇÃO**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXTwkiiGs2BV"
      },
      "source": [
        "Implementar um `notebook` no `Google Colab` que faça uso do framework **`LangChain`** (obrigatório) e de um **LLM** aplicando, no mínimo, uma técnica de PLN. A técnica pode ser aplicada em qualquer córpus. Também é obrigatório usar uma **API** da `ATIVIDADE PRÁTICA 03`. A **API** pode ser usada tanto para obter os dados quanto para disponibilizar os resultados.\n",
        "\n",
        "O **LLM** e a **API** selecionados devem ser informados na seguinte planilha:\n",
        "\n",
        "> https://docs.google.com/spreadsheets/d/1cOL7zVNffqmliuv23zFm1UJjhEXTdp1Zm5EyAJmhiKg/edit?usp=sharing\n",
        "\n",
        ">\n",
        "As seguintes técnicas de PLN podem ser usadas:\n",
        "\n",
        "*   Correção Gramatical\n",
        "*   Classificação de Textos\n",
        "*   Análise de Sentimentos\n",
        "*   Detecção de Emoções\n",
        "*   Extração de Palavras-chave\n",
        "*   Tradução de Textos\n",
        "*   Sumarização de Textos\n",
        "*   Similaridade de Textos\n",
        "*   Reconhecimento de Entidades Nomeadas\n",
        "*   Sistemas de Perguntas e Respostas\n",
        "\n",
        ">\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Lista de APIs:**\n",
        "\n",
        "\n",
        "* YouTube\n",
        "* LinkedIn\n",
        "* Twitter (X)\n",
        "* Facebook\n",
        "* Instagram\n",
        "* Medium\n",
        "* Reddit\n",
        "* TikTok\n",
        "* GitHub\n",
        "* Pinterest\n",
        "* Telegram\n",
        "* Dados financeiros\n",
        "* Notícias\n",
        "* Mercado de Ações\n",
        "* Dados financeiros\n",
        "* SMS\n",
        "* OpenAlex\n",
        "* Whisper (OpenAI)\n",
        "* Discord\n",
        "* Slack\n",
        "* Chuck Norris Jokes\n",
        "* Wikipedia\n",
        "* Last.fm\n",
        "* New York Times\n",
        "* Nasdaq Data Link\n",
        "* Yahoo! Finance\n",
        "* Twilio SendGrid Mail Send\n",
        "* Spotify\n",
        "* Awesome API\n",
        "* Google Books API\n",
        "* Mercado Livre API\n",
        "\n",
        ">\n",
        "\n",
        "**PLANILHA DA ATIVIDADE PRÁTICA 03:**\n",
        "\n",
        "> https://docs.google.com/spreadsheets/d/1-Q1szJ3UmoE2_3LtcRQyqid5fPIcnpsR3XAPnoxLj2o/edit?usp=sharing\n",
        "\n",
        "\n",
        "**IMPORTANTE:** É obrigatório usar o e-mail da UFABC.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWsBYQNtxmum"
      },
      "source": [
        "### **CRITÉRIOS DE AVALIAÇÃO**\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iHdx4BXYruQ"
      },
      "source": [
        "Serão considerados como critérios de avaliação os segunintes pontos:\n",
        "\n",
        "* Uso do framework **`LangChain`**.\n",
        "\n",
        "* Escolha e uso de um **LLM**.\n",
        "\n",
        "* Escolha e uso de uma **API**\n",
        "\n",
        "* Criatividade no uso do framework **`LangChain`** em conjunto com o **LLM** e a **API**.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhwdrMp123Xx"
      },
      "source": [
        "**IMPORTANTE**: todo o código do notebook deve ser executado. Código sem execução não será considerado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nw09lujGvfjc"
      },
      "source": [
        "# CONFIGURANDO AMBIENTES\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyUailD5vi9E",
        "outputId": "41f66c90-1cf0-4815-ff62-eb30a5f69a18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.19.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2023.11.17)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.0.350-py3-none-any.whl (809 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m809.1/809.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.23)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.2 (from langchain)\n",
            "  Downloading langchain_community-0.0.2-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2,>=0.1 (from langchain)\n",
            "  Downloading langchain_core-0.1.0-py3-none-any.whl (189 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.1/189.1 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.1.0,>=0.0.63 (from langchain)\n",
            "  Downloading langsmith-0.0.69-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain) (1.2.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, typing-inspect, langsmith, jsonpatch, langchain-core, dataclasses-json, langchain-community, langchain\n",
            "Successfully installed dataclasses-json-0.6.3 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.350 langchain-community-0.0.2 langchain-core-0.1.0 langsmith-0.0.69 marshmallow-3.20.1 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install huggingface_hub\n",
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exemplo de implementação"
      ],
      "metadata": {
        "id": "NoMO1V5zCo72"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuS_M987g6Im",
        "outputId": "407e52c4-a614-4730-beee-fcf14596a0e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ],
      "source": [
        "from getpass import getpass\n",
        "\n",
        "HUGGINGFACEHUB_API_TOKEN = getpass()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yooTAlrIhEkI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HUGGINGFACEHUB_API_TOKEN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLBI_ifZhJDm"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import HuggingFaceHub\n",
        "\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"Em 2015, foram encontradas grandes reservas de petróleo na região. Estima-se que na Guiana haja o equivalente a 11 bilhões de barris, parte significativa deles \"offshore\", ou seja, no mar, perto de Essequibo. Em consequência do boom do petróleo, a Guiana é o país sul-americano cuja economia mais cresce nos últimos anos. \"\"\"\n",
        "\n",
        "template = \"\"\"Summarize this text using just 10 words: {text}\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"text\"])"
      ],
      "metadata": {
        "id": "LcP872HR2NQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnDCYgl0tm0X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d67ed759-5312-4b68-d499-dac1846bb72a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:127: FutureWarning: '__init__' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
            "  warnings.warn(warning_message, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A Guiana é o pas sul-americano que tem o maior reserva de petróleo na regio.\n"
          ]
        }
      ],
      "source": [
        "repo_id = \"google/flan-t5-xxl\"  # See https://huggingface.co/models?pipeline_tag=text-generation&sort=downloads for some other options\n",
        "\n",
        "llm = HuggingFaceHub(\n",
        "    repo_id=repo_id, model_kwargs={\"temperature\": 1, \"max_length\": 128}\n",
        ")\n",
        "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "\n",
        "print(llm_chain.run(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# News API"
      ],
      "metadata": {
        "id": "x1ZPtqN23bn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "\n",
        "NEWS_API_TOKEN = getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbzkTYGj4fKb",
        "outputId": "08c4726f-f7df-4514-9cb9-5e4d904f7e07"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "response = requests.get(f\"https://newsapi.org/v2/everything?q=chatgpt&searchIn=content&language=pt&apiKey={NEWS_API_TOKEN}\")\n",
        "resJson = response.json()\n",
        "print(resJson['articles'][0]['title'])\n",
        "print(resJson['articles'][0]['description'])\n",
        "print(resJson['articles'][0]['content'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnFq0d4L4LOM",
        "outputId": "18dbdab9-e377-4dbf-9a49-cd08557655f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatGPT: OpenAI libera chats por voz para todos os usuários\n",
            "Inicialmente, recurso estava liberado apenas para usuários premium\n",
            "O post ChatGPT: OpenAI libera chats por voz para todos os usuários apareceu primeiro em Olhar Digital.\n",
            "A OpenAI anunciou a liberaÃ§Ã£o do recurso de chats por voz no ChatGPT para todos os usuÃ¡rios do chatbot no iOS e Android. Inicialmente, essa funÃ§Ã£o estava restrita aos assinantes do ChatGPT Plus.… [+2335 chars]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exemplo traduzindo manchetes sobre o ChatGPT"
      ],
      "metadata": {
        "id": "Ba4lr9iO-D9E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "response = requests.get(f\"https://newsapi.org/v2/everything?q=chatgpt&searchIn=content&language=pt&apiKey={NEWS_API_TOKEN}\")\n",
        "resJson = response.json()\n",
        "text = \"\"\n",
        "i = 0\n",
        "while i < 3 :\n",
        "  text = text + f\"{resJson['articles'][i]['title']} | {resJson['articles'][i]['description']}\\n\"\n",
        "  i = i + 1\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWYhQQAy-Of-",
        "outputId": "a5d0fa07-5ff2-4a6a-8d20-24b47860fc21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatGPT: OpenAI libera chats por voz para todos os usuários | Inicialmente, recurso estava liberado apenas para usuários premium\n",
            "O post ChatGPT: OpenAI libera chats por voz para todos os usuários apareceu primeiro em Olhar Digital.\n",
            "ChatGPT: como assinar o plano pago da inteligência artificial da OpenAI | ChatGPT Plus libera o GPT-4, modelo mais avançado que o GPT-3.5, e também oferece o acesso ao Dall-E\n",
            "O post ChatGPT: como assinar o plano pago da inteligência artificial da OpenAI apareceu primeiro em Olhar Digital.\n",
            "ChatGPT caiu? Chatbot apresenta instabilidade nesta terça-feira | Quem tentou usar o chatbot da OpenAI na noite desta terça-feira (21) provavelmente ficou frustrado; veja reclamações\n",
            "O post ChatGPT caiu? Chatbot apresenta instabilidade nesta terça-feira apareceu primeiro em Olhar Digital.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Traduzindo o conteúdo para Inglês"
      ],
      "metadata": {
        "id": "6j30Q_dGo-O1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"translate portuguese to english: {text}\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"text\"])"
      ],
      "metadata": {
        "id": "kOSlfFr7_qzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"translate this text in portuguese to english: {text}\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"text\"])\n",
        "\n",
        "repo_id = \"google/flan-t5-xxl\"  # See https://huggingface.co/models?pipeline_tag=text-generation&sort=downloads for some other options\n",
        "\n",
        "llm = HuggingFaceHub(\n",
        "    repo_id=repo_id, model_kwargs={\"temperature\": 0.5, \"max_length\": 400}\n",
        ")\n",
        "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "\n",
        "english_text = llm_chain.run(text)\n",
        "print(english_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Spd7qZZTmucz",
        "outputId": "84747978-f061-4a5d-949f-e19d6a020130"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:127: FutureWarning: '__init__' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
            "  warnings.warn(warning_message, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatGPT: OpenAI liberates voice chats for all users | Initially, the resource was only available for premium users O post ChatGPT: OpenAI liberates voice chats for all users appeared first on Digital Look.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Traduzindo conteúdo para o Alemão\n"
      ],
      "metadata": {
        "id": "-nDK1xYqowg2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"translate english to german: {english_text}\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"english_text\"])\n",
        "\n",
        "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "\n",
        "print(llm_chain.run(english_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWcf6TnckBI0",
        "outputId": "7fbbde5b-040d-4af1-f8c8-8c20592a22cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatGPT: OpenAI bietet Voice Chat für alle verfügbar | Im ursprünglichen Zustand war die Ressourcen nur für Premium-User verfügbar. Der O post ChatGPT: OpenAI bietet Voice Chat für alle erschien zuerst auf Digital Look.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Traduzindo conteúdo para o francês"
      ],
      "metadata": {
        "id": "NZPiZrHZpg3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"translate english to French: {english_text}\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"english_text\"])\n",
        "\n",
        "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "\n",
        "print(llm_chain.run(english_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQ4qUHI9pmeY",
        "outputId": "758a875b-9606-48e2-b108-29de1cf32bd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatGPT : OpenAI a publié un logiciel de chat en voix pour tous | Originally, the resource was only available to premium users Le post ChatGPT : OpenAI a publié un logiciel de chat en voix pour tous a apparu en premier sur Digital Look.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resumo de notícias\n"
      ],
      "metadata": {
        "id": "7tFTPcXWs_BI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "response = requests.get(f\"https://newsapi.org/v2/everything?q=palmeiras&searchIn=content&language=pt&apiKey={NEWS_API_TOKEN}\")\n",
        "resJson = response.json()\n",
        "print(resJson['articles'][0]['title'])\n",
        "print(resJson['articles'][0]['description'])\n",
        "print(resJson['articles'][0]['url'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3aV3P33_dfK",
        "outputId": "bbb94b29-ba9c-4984-d4f6-191e7e96859f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cruzeiro x Palmeiras: onde assistir, horário e escalações do jogo do Brasileirão\n",
            "Confira onde assistir, horário e prováveis escalações do confronto pela 38ª rodada do Campeonato Brasileiro de 2023\n",
            "O post Cruzeiro x Palmeiras: onde assistir, horário e escalações do jogo do Brasileirão apareceu primeiro em Olhar Digital.\n",
            "https://olhardigital.com.br/2023/12/06/internet-e-redes-sociais/cruzeiro-x-palmeiras-onde-assistir-horario-e-escalacoes-do-jogo-do-brasileirao/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "#define function to scrap information about the page\n",
        "def scrap_text_information(url) :\n",
        "   response = requests.get(url);\n",
        "   soup = BeautifulSoup(response.content, 'html.parser')\n",
        "   paragraphs = soup.find_all('p')                                                #correcao bia\n",
        "   scraped_text = '\\n'.join(paragraph.get_text() for paragraph in paragraphs)     #correcao bia\n",
        "\n",
        "   #scraped_text = soup.get_text()                                                #codigo origem\n",
        "   return scraped_text"
      ],
      "metadata": {
        "id": "5rmb1vA0Aog9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = scrap_text_information(resJson['articles'][0]['url'])\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3KlJur7_0YL",
        "outputId": "37f3f9a4-1bc2-4fb5-d5df-80faf6ddca26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nesta quarta-feira, 6 de dezembro, Cruzeiro e Palmeiras se enfrentam pela 38ª rodada do Campeonato Brasileiro de 2023. Os times jogam às 21h30 no Mineirão, em Belo Horizonte.\n",
            "Cruzeiro x Palmeiras\n",
            "Leia mais:\n",
            "A partida pela 38ª rodada do Brasileirão entre Cruzeiro e Palmeiras será transmitida na TV aberta pela Globo e na TV fechada pelo Premiere. (Para assinar o Premiere com sete dias grátis pelo Prime, clique aqui).\n",
            "Nos últimos confrontos pelo campeonato, o Cruzeiro venceu o Goiás por 1 a 0, empatou com o Athletico-PR por 1 a 1 e com o Botafogo por 0 a 0.\n",
            "A Raposa soma 46 pontos, com 11 vitórias, 13 empates e 13 derrotas.\n",
            "O Palmeiras chega para o confronto após empatar com o Fortaleza por 2 a 2, vencer o América-MG por 4 a 0 e o Fluminense por 1 a 0.\n",
            "O Verdão soma 69 pontos, com 20 vitórias, 9 empates e 8 derrotas.\n",
            "Jornalista em formação pela Universidade Metodista de São Paulo (UMESP). Mesmo com alguns assuntos negativos, gosta ficar atualizado e noticiar o que há de novo na tecnologia.\n",
            "Bruno Capozzi é jornalista formado pela Faculdade Cásper Líbero e mestre em Ciências Sociais pela PUC-SP, tendo como foco a pesquisa de redes sociais e tecnologia.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"summarize this article: {text}\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"text\"])\n",
        "\n",
        "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "\n",
        "print(llm_chain.run(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9aPl-8zsOZ3",
        "outputId": "db2a3d2a-bd10-4633-bedc-98123b7bbf9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columbia University Administrators covertly changed events policies before suspending two pro-Palestine student groups, according to the university government.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tradução de notícias"
      ],
      "metadata": {
        "id": "AVmnHJS_CGh6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "response = requests.get(f\"https://newsapi.org/v2/everything?q=palestine&searchIn=content&language=en&apiKey={NEWS_API_TOKEN}\")\n",
        "resJson = response.json()\n",
        "print(resJson['articles'][0]['title'])\n",
        "print(resJson['articles'][0]['description'])\n",
        "print(resJson['articles'][0]['url'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xq-N7Ic_CZfw",
        "outputId": "4c988bfa-7413-48e8-8b8e-e0a9395ca958"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columbia administrators reportedly covertly changed the university's event policies just before suspending pro-Palestine student groups\n",
            "A Columbia University executive confirmed that administrators unilaterally revised policies before suspending two pro-Palestine student groups.\n",
            "https://www.businessinsider.com/report-columbia-university-changed-policies-before-pro-palestine-group-suspensions-2023-11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = scrap_text_information(resJson['articles'][0]['url'])\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mg6JH49QC0No",
        "outputId": "9f99f980-34d8-456c-df8b-6751ba93e722"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jump to\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Columbia University Administrators covertly changed events policies before suspending two pro-Palestine student groups, according to the university government.\n",
            "Gerald M. Rosberg, senior executive vice president of the university, informed the University Senate on Friday that university administrators had revised the policies without the knowledge of the senate, according to Columbia Spectator.\n",
            "\"I know I am going to be living with this for a long time to come,\" Rosberg said at the meeting according to the student newspaper.\n",
            "The war between Israel and Hamas has become a controversial topic on college campuses throughout the U.S. since Hamas' October 7 attack inside Israel, which killed 1,200 people.\n",
            "Israel responded with air attacks and a ground invasion in Gaza that have so far killed more than 10,000 Palestinians, thousands of whom are believed to be children, according to the Hamas-led Palestinian Health Ministry.\n",
            "A growing pro-Palestinian activist movement at American schools and colleges has stoked controversy and has been covered extensively in the media. For instance, in California, a first grade teacher was suspended for giving students a lesson about the \"genocide in Palestine.\" At the University of Pennsylvania, the decision to host a Palestine Writes Literary Festival caused several mega-donors to threaten their support for the school.\n",
            "According to Spectator, Columbia changed its events policy after student chapters of Students for Justice in Palestine and Jewish Voice for Peace protested on October 12.\n",
            "Columbia ultimately suspended the university chapters of SJP and JVP on November 10 after the groups organized a walkout, which it says were in violation of the policies.\n",
            "Jeanine D'Armiento, University Senate executive committee chair, said the policy change is an \"inconsistency in the events and the rules\" and that she is \"not going to accept any explanation\" that the communication of the policy change was made clear,\" Spectator reported.\n",
            "David Lurie, president of the Columbia chapter of the American Association of University Professors, said that administrators updating student group policies on their own was a \"gross violation\" of shared governance, according to Inside Higher Ed.\n",
            "\"What they've done is taken something that should be running through existing disciplinary channels that involve our right of appeal, that involve advisory boards, that include faculty and student representation, and eliminated all of those,\" he told the outlet.\n",
            "Columbia did not immediately return Insider's request for comment Saturday, but a university spokesperson told Inside Higher Ed that the university sent the student groups \"restatements\" of the policy updates before the walkout that led to their suspension.\n",
            "\"[The groups'] compliance with [the procedures] started to slip, and the [groups'] advisers issued numerous warnings that clearly laid out that failure to respect the required processes would have consequences,\" the spokesperson said.\n",
            "\n",
            "                          Read next\n",
            "                        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"translate english to french: {text}\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"text\"])\n",
        "\n",
        "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "\n",
        "print(llm_chain.run(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_MPm3byDRWL",
        "outputId": "7ea70f7d-9542-45a0-f2e2-fdb8fdf046bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " la suite de cette attaque, Isral a retiré la paix avec les palestiniens et il a entraîné des mesures militaires et aériennes contre les palestiniens, à savoir la bombardement des aéroports, et l'invasion humaine à Gaza, et Isral a en revanche retiré la paix avec les palestiniens et à l'entraide des palestiniens, d'après le Ministère palestinien de la santé dirigé par Hamas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Extra : Sistemas de perguntas e respostas**\n",
        "\n",
        "Colocamos essa seção como extra no trabalho pois o limite de utilização do GTP4ALL foi atingido.\n",
        "\n"
      ],
      "metadata": {
        "id": "RejGPS5CdrKO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A implementação abaixo utiliza :\n",
        "\n",
        "API GPT4All (https://github.com/nomic-ai/gpt4all)\n",
        "\n",
        "LLM Falcon(https://falconllm.tii.ae/)\n",
        "\n",
        "LLaMA (https://ai.meta.com/blog/large-language-model-llama-meta-ai/)"
      ],
      "metadata": {
        "id": "KphP8p5PnXeZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Configurando Ambientes\n",
        "!pip install langchain\n",
        "%pip install gpt4all > /dev/null"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UKZ1ofpaQem",
        "outputId": "d8ac2a64-b456-4c03-eb7c-2f9d9aff1a6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.0.348-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.23)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-core<0.1,>=0.0.12 (from langchain)\n",
            "  Downloading langchain_core-0.0.12-py3-none-any.whl (181 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.5/181.5 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.1.0,>=0.0.63 (from langchain)\n",
            "  Downloading langsmith-0.0.69-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.1,>=0.0.12->langchain) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.1,>=0.0.12->langchain) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.1,>=0.0.12->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.1,>=0.0.12->langchain) (1.2.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, typing-inspect, langsmith, jsonpatch, langchain-core, dataclasses-json, langchain\n",
            "Successfully installed dataclasses-json-0.6.3 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.348 langchain-core-0.0.12 langsmith-0.0.69 marshmallow-3.20.1 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Sistema de Perguntas e respostas:\n",
        "\n",
        "Insira a pergunta na linha 4, e calibre a quantidade de palavras (tokens) da resposta esperada conforme os exemplos abaixo"
      ],
      "metadata": {
        "id": "KsMRPD15qk1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gpt4all import GPT4All\n",
        "model = GPT4All(\"gpt4all-falcon-q4_0.gguf\")\n",
        "output = model.generate(\"What is the difference between a cat and a dog?\", max_tokens=100)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jENMZ9BPjkiw",
        "outputId": "eb3aa739-54d7-4a56-a373-b5818f8ae166"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.21G/4.21G [02:18<00:00, 30.4MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cats are more independent, have shorter hair, and are generally more agile. Dogs are more social, have longer hair, and are typically larger in size. Additionally, cats are carnivorous while dogs can eat both meat and vegetables.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gpt4all import GPT4All\n",
        "model = GPT4All(\"nous-hermes-llama2-13b.Q4_0.gguf\")\n",
        "output = model.generate(\"What is the difference between a cat and a dog?\", max_tokens=100)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PDw2T4RoNYv",
        "outputId": "e7963a33-1355-4e4d-f8fc-f56547485135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7.37G/7.37G [04:25<00:00, 27.7MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "A cat uses its whiskers to sense its surroundings, while a dog relies on its nose. Cats are generally more independent than dogs and require less attention from their owners. Dogs are known for their loyalty and obedience, often serving as protectors or assisting in tasks such as hunting or guiding the visually impaired.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "RejGPS5CdrKO",
        "KsMRPD15qk1e",
        "DVCQ1OC2q5YU"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}